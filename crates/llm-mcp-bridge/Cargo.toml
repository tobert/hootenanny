[package]
name = "llm-mcp-bridge"
version = "0.1.0"
edition = "2021"
description = "LLM â†” MCP tool bridge with agent loop"

[dependencies]
# OpenAI API
async-openai = "0.28"

# MCP integration
baton = { path = "../baton" }
llmchat = { path = "../llmchat" }

# Async runtime
tokio = { version = "1", features = ["sync", "time", "rt"] }
async-trait = "0.1"
futures = "0.3"

# HTTP client for MCP calls
reqwest = { version = "0.12", features = ["json"] }

# Serialization
serde = { version = "1", features = ["derive"] }
serde_json = "1"
schemars = "1"

# Error handling
anyhow = "1"
thiserror = "1"

# Utilities
uuid = { version = "1", features = ["v4"] }
chrono = { version = "0.4", features = ["serde"] }

# Tracing
tracing = "0.1"
opentelemetry = { version = "0.28", features = ["trace"] }
tracing-opentelemetry = "0.29"

[dev-dependencies]
tokio = { version = "1", features = ["full", "test-util"] }
wiremock = "0.6"
